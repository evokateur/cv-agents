{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u41192vvkpl",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the new embedding tool\n",
    "\n",
    "from embedding_tool import KnowledgeBaseEmbedder\n",
    "\n",
    "# Create embedder instance\n",
    "embedder = KnowledgeBaseEmbedder()\n",
    "\n",
    "# Create embeddings and get statistics\n",
    "result = embedder.create_embeddings()\n",
    "\n",
    "# Display results\n",
    "print(f\"Status: {result['status']}\")\n",
    "print(f\"Message: {result['message']}\")\n",
    "print(f\"Documents loaded: {result['documents_loaded']}\")\n",
    "print(f\"Chunks created: {result['chunks_created']}\")\n",
    "print(f\"Vectors stored: {result['vectors_stored']}\")\n",
    "print(f\"Vector dimensions: {result['vector_dimensions']}\")\n",
    "print(f\"Document types found: {', '.join(result['doc_types'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43qu1bb4lu3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test retrieval from the new vectorstore\n",
    "\n",
    "vectorstore = embedder.get_vectorstore()\n",
    "\n",
    "if vectorstore:\n",
    "    # Test a sample query\n",
    "    query = \"software development experience\"\n",
    "    results = vectorstore.similarity_search(query, k=3)\n",
    "    \n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(f\"Found {len(results)} relevant documents:\")\n",
    "    print()\n",
    "    \n",
    "    for i, doc in enumerate(results, 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"  Doc type: {doc.metadata.get('doc_type', 'unknown')}\")\n",
    "        print(f\"  Source: {doc.metadata.get('source', 'unknown')}\")\n",
    "        print(f\"  Content preview: {doc.page_content[:200]}...\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"No vectorstore found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "v144uvi2jyk",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the web scraper tool\n",
    "\n",
    "from cv_agents.tools.web_scraper import job_posting_scraper\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Test URL from implementation plan\n",
    "test_url = \"https://app.welcometothejungle.com/dashboard/jobs/oA1SArxV\"\n",
    "\n",
    "print(f\"Testing web scraper with URL: {test_url}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "try:\n",
    "    # Extract job posting\n",
    "    job_posting = job_posting_scraper._run(test_url)\n",
    "    \n",
    "    print(\"‚úÖ Successfully extracted job posting!\")\n",
    "    print()\n",
    "    print(f\"Title: {job_posting.title}\")\n",
    "    print(f\"Company: {job_posting.company}\")\n",
    "    print(f\"Experience Level: {job_posting.experience_level}\")\n",
    "    print(f\"Industry: {job_posting.industry}\")\n",
    "    print()\n",
    "    print(f\"Skills ({len(job_posting.skills)}): {', '.join(job_posting.skills)}\")\n",
    "    print()\n",
    "    print(f\"Requirements ({len(job_posting.requirements)}):\")\n",
    "    for i, req in enumerate(job_posting.requirements, 1):\n",
    "        print(f\"  {i}. {req}\")\n",
    "    print()\n",
    "    print(f\"Description (first 300 chars): {job_posting.description[:300]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "    job_posting = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pvhx1n16pbp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save job posting to persistence directory\n",
    "\n",
    "if job_posting:\n",
    "    # Create filename with timestamp and sanitized company/title\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    safe_company = \"\".join(c for c in job_posting.company if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    safe_title = \"\".join(c for c in job_posting.title if c.isalnum() or c in (' ', '-', '_')).rstrip()\n",
    "    \n",
    "    filename = f\"{timestamp}_{safe_company}_{safe_title}.json\".replace(\" \", \"_\")\n",
    "    filepath = f\"job_postings/{filename}\"\n",
    "    \n",
    "    # Convert to dict and save as JSON\n",
    "    job_data = job_posting.model_dump()\n",
    "    job_data[\"scraped_at\"] = datetime.now().isoformat()\n",
    "    job_data[\"source_url\"] = test_url\n",
    "    \n",
    "    with open(filepath, 'w', encoding='utf-8') as f:\n",
    "        json.dump(job_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"üíæ Job posting saved to: {filepath}\")\n",
    "    print(f\"üìÑ File size: {len(json.dumps(job_data, indent=2))} bytes\")\n",
    "    \n",
    "    # Show the JSON structure\n",
    "    print()\n",
    "    print(\"üìã Saved data structure:\")\n",
    "    for key, value in job_data.items():\n",
    "        if isinstance(value, list):\n",
    "            print(f\"  {key}: [{len(value)} items]\")\n",
    "        elif isinstance(value, str) and len(value) > 50:\n",
    "            print(f\"  {key}: '{value[:50]}...'\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "else:\n",
    "    print(\"‚ùå No job posting data to save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV Agents",
   "language": "python",
   "name": "cv-agents"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
